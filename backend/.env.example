# =============================================================================
# Backend Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose your primary LLM provider: openai, anthropic, or openrouter
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration (optional, for Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229

# OpenRouter Configuration (optional, for unified access to multiple providers)
OPENROUTER_API_KEY=your-openrouter-api-key-here
OPENROUTER_MODEL=anthropic/claude-3-opus

# =============================================================================
# Knowledge Base Configuration
# =============================================================================
# Knowledge Base API URL
KB_SERVICE_URL=http://localhost:8000

# Direct Elasticsearch connection (optional, for advanced queries)
ELASTICSEARCH_URL=http://localhost:9200
KB_INDEX_NAME=open_rabbit_knowledge_base

# Embedding model for KB queries
KB_EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL connection
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/openrabbit

# =============================================================================
# Server Configuration
# =============================================================================
# Backend API server
HOST=0.0.0.0
PORT=8080

# =============================================================================
# Supervisor Agent Configuration
# =============================================================================
# Enable Knowledge Base integration
KB_ENABLED=true

# Enable checkpointing for restart capability
ENABLE_CHECKPOINTING=true

# Agent timeout in seconds
AGENT_TIMEOUT=600

# Maximum retries for failed agents
MAX_RETRIES=3

# Use mock agents for testing (set to true for development without LLM API)
USE_MOCK_AGENTS=false

# =============================================================================
# Logging and Telemetry
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# OpenTelemetry configuration (optional)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=openrabbit-backend

# =============================================================================
# GitHub Integration
# =============================================================================
# GitHub App credentials (if using GitHub integration)
GITHUB_APP_ID=
GITHUB_PRIVATE_KEY=
GITHUB_WEBHOOK_SECRET=

# =============================================================================
# Redis (for task queue, optional)
# =============================================================================
REDIS_URL=redis://localhost:6379/0
